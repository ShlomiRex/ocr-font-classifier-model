{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 760\n"
     ]
    }
   ],
   "source": [
    "FONTS = ['Skylark', 'Ubuntu Mono', 'Sweet Puppy']\n",
    "\n",
    "file_name = \"font_recognition_train_set/SynthText.h5\"\n",
    "\n",
    "db = h5py.File(file_name, \"r\")\n",
    "IM_NAMES = list(db[\"data\"].keys())\n",
    "\n",
    "num_of_images = len(im_names)\n",
    "print(f\"Number of images: {num_of_images}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop the word with perfect angle - affine transformation\n",
    "\n",
    "Tutorial that helped me:\n",
    "\n",
    "https://docs.opencv.org/3.4/d4/d61/tutorial_warp_affine.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_affine(img, bb):\n",
    "    \"\"\"\n",
    "    Crop image using affine transformation, around bounding box. Returns cropped image.\n",
    "    \"\"\"\n",
    "    img_copy = img.copy()\n",
    "    width = img_copy.shape[1]\n",
    "    height = img_copy.shape[0]\n",
    "    \n",
    "    point1 = (bb[0][0], bb[1][0]) # Top-left\n",
    "    point2 = (bb[0][1], bb[1][1]) # Top-right\n",
    "    point3 = (bb[0][2], bb[1][2]) # Bottom-Right\n",
    "    point4 = (bb[0][3], bb[1][3]) # Bottom-Left\n",
    "    \n",
    "    #mapping srcPoints (list of points of size 3) to dstPoints (list of points of size 3)\n",
    "    srcTri = np.array( [point1, point2, point4] ).astype(np.float32)\n",
    "    dstTri = np.array( [[0, 0], [width, 0], [0, height]] ).astype(np.float32)\n",
    "    \n",
    "    warp_mat = cv2.getAffineTransform(srcTri, dstTri)\n",
    "    warp_dst = cv2.warpAffine(img_copy, warp_mat, (width, height))\n",
    "    \n",
    "    return warp_dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize function\n",
    "\n",
    "![](images/normalize_formula.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img, low=0, high=1):\n",
    "    \"\"\"\n",
    "    Normalize image to range [low, high] from any range. Note: fast algorithm.\n",
    "    \"\"\"\n",
    "    return np.interp(img, [np.min(img), np.max(img)], [low, high])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(img_name):\n",
    "    \"\"\"\n",
    "    Process the image and returned processed result.\n",
    "    Return a json in the following structure (as an example):\n",
    "    \n",
    "    {\n",
    "        \"name\": \"test.png\",\n",
    "        \"words\": [\n",
    "            {\n",
    "                \"word\": \"the\",\n",
    "                \"font\": \"Ubuntu Mono\",\n",
    "                \"chars\": [\n",
    "                    {\n",
    "                        \"char\": \"t\",\n",
    "                        \"font\": \"Ubuntu Mono\",\n",
    "                        \"crop\": <ndarray>\n",
    "                    }, ...\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"word\": \"shlomi\",\n",
    "                \"font\": \"Skylark\",\n",
    "                \"chars\": [\n",
    "                    {\n",
    "                        \"char\": \"s\",\n",
    "                        \"font\": \"Skylark\",\n",
    "                        \"crop\": <ndarray>\n",
    "                    }, ...\n",
    "                ]\n",
    "            }, ...\n",
    "        ]\n",
    "    }\n",
    "    \"\"\"\n",
    "    img = db['data'][img_name][:]\n",
    "    font = db['data'][img_name].attrs['font']\n",
    "    txt = db['data'][img_name].attrs['txt']\n",
    "    charBB = db['data'][img_name].attrs['charBB'] # Contains list of bb for words.\n",
    "    wordBB = db['data'][img_name].attrs['wordBB'] # Contain list of bb for chars.\n",
    "\n",
    "\n",
    "    words = []\n",
    "    char_index_accumulator = 0\n",
    "    word_index = 0 # Counter\n",
    "    \n",
    "    # Process word\n",
    "    for word in txt:\n",
    "        word_font = font[char_index_accumulator].decode() # Convert bytes to string\n",
    "        chars = []\n",
    "        word_bb = wordBB[:, :, word_index]\n",
    "        \n",
    "        # Process chars\n",
    "        for char_index in range(len(word)):\n",
    "            char = chr(word[char_index])\n",
    "            char_font = font[char_index_accumulator].decode()\n",
    "            char_bb = charBB[:, :, char_index_accumulator]\n",
    "            \n",
    "            assert char_font == word_font # Double check that the pre-processed image is indeed 1 font per word, and each char is same font as word.\n",
    "            \n",
    "            crop_char = crop_affine(img, char_bb)\n",
    "            \n",
    "            chars.append({\n",
    "                \"char\": char,\n",
    "                \"font\": char_font,\n",
    "                \"crop\": crop_char\n",
    "            })\n",
    "            \n",
    "            char_index_accumulator += 1\n",
    "\n",
    "        words.append({\n",
    "            \"word\": word.decode(),\n",
    "            \"font\": word_font,\n",
    "            \"chars\": chars\n",
    "        })\n",
    "        word_index += 1\n",
    "    \n",
    "    # Return result\n",
    "    return {\n",
    "        \"name\": img_name,\n",
    "        \"words\": words,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train = [] #Images\n",
    "y_train = [] #Labels\n",
    "i = 0\n",
    "for img_name in im_names:\n",
    "    res = extract_data(img_name)\n",
    "    for word in res[\"words\"]:\n",
    "        for char in word[\"chars\"]:\n",
    "            char_font = char[\"font\"]\n",
    "            char_crop = char[\"crop\"]\n",
    "            x_train.append(char_crop)\n",
    "            y_train.append(char_font)\n",
    "            if i == 10:\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size=0.2, random_state=12345)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "598"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_validate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
