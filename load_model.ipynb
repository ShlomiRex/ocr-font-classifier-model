{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Notify when finished training\n",
    "%load_ext jupyternotify\n",
    "\n",
    "\n",
    "print(\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "FONTS = ['Skylark', 'Ubuntu Mono', 'Sweet Puppy']\n",
    "# Pre-calculated average width, height of all cropped train data\n",
    "AVG_CHAR_WIDTH = 28\n",
    "AVG_CHAR_HEIGHT = 49\n",
    "\n",
    "train_filename = \"font_recognition_train_set/SynthText.h5\"\n",
    "val_filename = \"validation_set/SynthText_val.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 41, 20, 128)       10496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 20, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 18, 8, 256)        295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 9, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 7, 2, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 3, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1024)              1573888   \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 4,112,387\n",
      "Trainable params: 4,112,387\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = keras.models.load_model(\"saved_model.h5\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# func: Create x,y sets from h5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate(filename, X, Y):\n",
    "    \"\"\"\n",
    "    filename - h5 file to read from\n",
    "    X - array to populate\n",
    "    Y - array to populate\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read from db\n",
    "    db = h5py.File(filename, \"r\")\n",
    "    im_names = list(db[\"data\"].keys())\n",
    "    num_of_images = len(im_names)\n",
    "    print(f\"Number of images: {num_of_images}\")\n",
    "    \n",
    "    for img_name in im_names:\n",
    "        res = extract_data(db, img_name)\n",
    "        for word in res[\"words\"]:\n",
    "            for char in word[\"chars\"]:\n",
    "                char_font = char[\"font\"]\n",
    "                char_crop = char[\"crop\"]\n",
    "\n",
    "                # There are some images with defect bounding boxes (image: hubble_22.jpg)\n",
    "                if char_crop.shape[0] == 0 or char_crop.shape[1] == 0:\n",
    "                    word_str = word[\"word\"]\n",
    "                    char_str = char[\"char\"]\n",
    "                    print(f\"Invalid crop at image: {img_name}, word: {word_str}, char: {char_str}\")\n",
    "                else:\n",
    "                    append_to_set (X, Y, char_crop, char_font, noisy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# func: Crop the word with perfect angle - affine transformation\n",
    "\n",
    "Tutorial that helped me:\n",
    "\n",
    "https://docs.opencv.org/3.4/d4/d61/tutorial_warp_affine.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_affine(img, bb):\n",
    "    \"\"\"\n",
    "    Crop image using affine transformation, around bounding box. Returns cropped image.\n",
    "    \"\"\"\n",
    "    img_copy = img.copy()\n",
    "    width = img_copy.shape[1]\n",
    "    height = img_copy.shape[0]\n",
    "        \n",
    "    point1 = (bb[0][0], bb[1][0]) # Top-left\n",
    "    point2 = (bb[0][1], bb[1][1]) # Top-right\n",
    "    point3 = (bb[0][2], bb[1][2]) # Bottom-Right\n",
    "    point4 = (bb[0][3], bb[1][3]) # Bottom-Left\n",
    "    \n",
    "    # Euclidian distance\n",
    "    bb_width = int(np.linalg.norm(np.array(point1) - np.array(point2)))\n",
    "    bb_height = int(np.linalg.norm(np.array(point1) - np.array(point3)))\n",
    "\n",
    "    # Mapping srcPoints (list of points of size 3) to dstPoints (list of points of size 3)\n",
    "    srcTri = np.array( [point1, point2, point4] ).astype(np.float32)\n",
    "    dstTri = np.array( [[0, 0], [bb_width, 0], [0, bb_height]] ).astype(np.float32)\n",
    "    \n",
    "    # Apply transformation\n",
    "    warp_mat = cv2.getAffineTransform(srcTri, dstTri)\n",
    "    warp_dst = cv2.warpAffine(img_copy, warp_mat, (width, height))\n",
    "    \n",
    "    # Crop the 'warped' image\n",
    "    crop = warp_dst[0:bb_height, 0:bb_width]\n",
    "    \n",
    "    return crop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# func: Extract data from image name return json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(db, img_name:str):\n",
    "    \"\"\"\n",
    "    Process the image and returned processed result.\n",
    "    Parameter db is h5 database read from file.\n",
    "    Return a json in the following structure (as an example):\n",
    "    {\n",
    "        \"img\": <ndarray>,\n",
    "        \"name\": \"test.png\",\n",
    "        \"words\": [\n",
    "            {\n",
    "                \"word\": \"the\",\n",
    "                \"font\": \"Ubuntu Mono\",\n",
    "                \"chars\": [\n",
    "                    {\n",
    "                        \"char\": \"t\",\n",
    "                        \"font\": \"Ubuntu Mono\",\n",
    "                        \"crop\": <ndarray>,\n",
    "                        \"bb\": <ndarray>\n",
    "                    }, ...\n",
    "                ],\n",
    "                \"bb\": <ndarray>\n",
    "                \"crop\": <ndarray>\n",
    "            }, ...\n",
    "        ]\n",
    "    }\n",
    "    \"\"\"\n",
    "    img = db['data'][img_name][:]                 # The image.\n",
    "    font = db['data'][img_name].attrs['font']     # Contains list of fonts.\n",
    "    txt = db['data'][img_name].attrs['txt']       # Contains list of words.\n",
    "    charBB = db['data'][img_name].attrs['charBB'] # Contains list of bb for words.\n",
    "    wordBB = db['data'][img_name].attrs['wordBB'] # Contain list of bb for chars.\n",
    "\n",
    "\n",
    "    words = []\n",
    "    char_index_accumulator = 0\n",
    "    word_index = 0 # Counter\n",
    "    \n",
    "    # Process word\n",
    "    for word in txt:\n",
    "        word_font = font[char_index_accumulator].decode() # Convert bytes to string\n",
    "        chars = []\n",
    "\n",
    "        word_bb = wordBB[:, :, word_index]\n",
    "        word_crop = crop_affine(img, word_bb)\n",
    "\n",
    "        # Process chars\n",
    "        for char_index in range(len(word)):\n",
    "            char = chr(word[char_index])\n",
    "            char_font = font[char_index_accumulator].decode()\n",
    "            char_bb = charBB[:, :, char_index_accumulator]\n",
    "            \n",
    "            #assert char_font == word_font # Double check that the pre-processed image is indeed 1 font per word, and each char is same font as word.\n",
    "            \n",
    "            crop_char = crop_affine(img, char_bb)\n",
    "            \n",
    "            chars.append({\n",
    "                \"char\": char,\n",
    "                \"font\": char_font,\n",
    "                \"crop\": crop_char,\n",
    "                \"bb\": char_bb\n",
    "            })\n",
    "            \n",
    "            char_index_accumulator += 1\n",
    "\n",
    "        words.append({\n",
    "            \"word\": word.decode(),\n",
    "            \"font\": word_font,\n",
    "            \"chars\": chars,\n",
    "            \"bb\": word_bb,\n",
    "            \"crop\": word_crop,\n",
    "        })\n",
    "        word_index += 1\n",
    "    \n",
    "    # Return result\n",
    "    return {\n",
    "        \"img\": img,\n",
    "        \"name\": img_name,\n",
    "        \"words\": words,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# func: Process image and label and append to training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_set(X, Y, x, y, noisy=True):\n",
    "    \"\"\"\n",
    "    Append (x,y) sample to (X,Y) arrays. Checking correct font (y) and shape of image (x).\n",
    "    Set noisy to False if you don't want to convert image 'x' to noisy image and appending it (append 'x' without modification).\n",
    "    \"\"\"\n",
    "    # Convert to gray\n",
    "    try:\n",
    "        if x.shape[2] != 1:\n",
    "            x = cv2.cvtColor(x, cv2.COLOR_BGR2GRAY)\n",
    "    except:\n",
    "        pass\n",
    "    # Resize\n",
    "    if x.shape[0] != AVG_CHAR_HEIGHT or x.shape[1] != AVG_CHAR_WIDTH:\n",
    "        x = cv2.resize(x, (AVG_CHAR_WIDTH, AVG_CHAR_HEIGHT))\n",
    "    # Normalize\n",
    "    x = normalize(x)\n",
    "    \n",
    "    # Map y string to float\n",
    "    if type(y) == str:\n",
    "        if y == \"Ubuntu Mono\":\n",
    "            y = 0\n",
    "        elif y == \"Skylark\":\n",
    "            y = 1\n",
    "        elif y == \"Sweet Puppy\":\n",
    "            y = 2\n",
    "        else:\n",
    "            raise \"Error font, no such font: \" + str(y)\n",
    "    \n",
    "    if noisy:\n",
    "        x = noisy(x)\n",
    "    \n",
    "    X.append(x)\n",
    "    Y.append(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# func: Normalize function\n",
    "\n",
    "![](images/normalize_formula.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img, low=0, high=1):\n",
    "    \"\"\"\n",
    "    Normalize image to range [low, high] from any range. Note: fast algorithm.\n",
    "    \"\"\"\n",
    "    return np.interp(img, [np.min(img), np.max(img)], [low, high])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 520\n",
      "x_val length: 8198 y_val length: 8198\n",
      "CPU times: user 44.6 s, sys: 41.1 s, total: 1min 25s\n",
      "Wall time: 9.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_val = [] #Images\n",
    "y_val = [] #Labels\n",
    "\n",
    "populate(val_filename, x_val, y_val)\n",
    "print(f\"x_val length: {len(x_val)} y_val length: {len(y_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X val shape:  (8198, 49, 28, 1)\n",
      "Y val shape:  (8198,)\n"
     ]
    }
   ],
   "source": [
    "X_val = np.array(x_val)\n",
    "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], X_val.shape[2], 1)\n",
    "Y_val = np.array(y_val)\n",
    "\n",
    "print(\"X val shape: \", X_val.shape)\n",
    "print(\"Y val shape: \", Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on validation data\n",
      "65/65 [==============================] - 8s 123ms/step - loss: 0.1964 - accuracy: 0.9523\n",
      "val loss, val acc: [0.19643855094909668, 0.9523054361343384]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_val, Y_val, batch_size=128)\n",
    "print(\"val loss, val acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val[0:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
